{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3551087,"sourceType":"datasetVersion","datasetId":2135106}],"dockerImageVersionId":30176,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bike Maintenance and Repair Analysis\nWorking as Head Mechanic and Assistant Area Manager for 2 years for the #1 Recreation Rentals by Entrepreneur Magazine for 5 years. I set up a free product management system for the four locations I grew into with 10 product types with 300+ total products with 400 reports from January 2020 to September 2021 where I and a part time mechanic managed with no prior mechanic experience using Notion for managment and data collection and Chillipepper API for a QR Code for team members to report when bikes were down to give live status on locations.\n\n## Objective of Analysis\n- Analyze the frequency and types of bike breakdowns\n- Evaluate the efficiency of the repair process\n- Identify trends and patterns in bike maintenance\n\n## Dataset Description\n- Down Date : The date and time the bike was reported broken\n- Fixed Date : The date and time the bike was reported fixed\n- Location : Catagorical location of the bike that was broken \n    - Mile Square Park ( Edinger and Warner) Waterfront Adventures, Yorba Linda Regional Park\n- Description: Description by team member of the problem of the product\n- Product: Catagorical of 10 products including; \n    Swan Boats, Kayaks, Single and Double Surreys, Specialty Products (Deuce Coupe, Quad Sport, Chopper), Cruisers (Adult/Kids), E-Bikes (Waterfront Only),and Tandem Bikes.\n    \n## Analysis Questions\n1. How much productivity did the system bring over the two years?\n   - With a moving average per week beginning in November in 2020 with around 150 days to having a moving average to be withing 50 to 0 days by March 2021 and keeping it below 25 days during peak months in 2021. See Productivity Heading \n2. What was busiest location in relation to the parks attendence? (Only Mile Square)\n3. Rank the most successfully maintained locaitons? Does the priorty match?\n    Under Medians and Averages by Locations\n    1. Yorba (Average of 20 days and Median of 6 days) \n    2. Edinger (Average of 21 days and Median of 7 days)\n    3. Watefront (Average of 39 days and Median of 14 days)\n    4. Warner (Average of 45 days and median of 42 days) \n4. Was there any reoccuring problems? Flat Tires, broken wheels, etc.?\n5. Did implementing a daily to do list and self inspection for mechanics and team members for slow times have a positive effect on the product? \n    - (08/20) Daily Team Memeber Task Sheet\n        - Including bike maintaince tasks like putting air in the tires, and tightening chains.\n    - (03/21) Mechanic Self Inspection Form ","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport os\nimport warnings\nimport datetime\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn import preprocessing \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T19:30:50.900050Z","iopub.execute_input":"2024-07-07T19:30:50.900380Z","iopub.status.idle":"2024-07-07T19:30:50.907377Z","shell.execute_reply.started":"2024-07-07T19:30:50.900342Z","shell.execute_reply":"2024-07-07T19:30:50.906447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/wheelfun-database/MB_Reports.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:50.908831Z","iopub.execute_input":"2024-07-07T19:30:50.909165Z","iopub.status.idle":"2024-07-07T19:30:50.924170Z","shell.execute_reply.started":"2024-07-07T19:30:50.909127Z","shell.execute_reply":"2024-07-07T19:30:50.923141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Uncleaned Data Exploring\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\ndf['Location'].hist()\nplt.title('Reports by Location')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:50.925579Z","iopub.execute_input":"2024-07-07T19:30:50.925893Z","iopub.status.idle":"2024-07-07T19:30:51.172213Z","shell.execute_reply.started":"2024-07-07T19:30:50.925848Z","shell.execute_reply":"2024-07-07T19:30:51.171136Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\ndf['Product'].hist()\nplt.title('Reports by Product')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.174148Z","iopub.execute_input":"2024-07-07T19:30:51.174427Z","iopub.status.idle":"2024-07-07T19:30:51.431273Z","shell.execute_reply.started":"2024-07-07T19:30:51.174394Z","shell.execute_reply":"2024-07-07T19:30:51.430388Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.count()\n# Should be about 450 - 540 total reports based on required input (Description, Location, and Status column counts)\n# Deleting the Location_Part columns (Ex.'Warner Part') due to operational use only for orederiing parts.\n# Deleting the Attatchment feature column that stored photos of the broken part that needed to replaced for easy communication","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.432775Z","iopub.execute_input":"2024-07-07T19:30:51.433107Z","iopub.status.idle":"2024-07-07T19:30:51.443836Z","shell.execute_reply.started":"2024-07-07T19:30:51.433047Z","shell.execute_reply":"2024-07-07T19:30:51.442941Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.444886Z","iopub.execute_input":"2024-07-07T19:30:51.445126Z","iopub.status.idle":"2024-07-07T19:30:51.471517Z","shell.execute_reply.started":"2024-07-07T19:30:51.445068Z","shell.execute_reply":"2024-07-07T19:30:51.470622Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()\n# Lots of null values when first starting to use the reports that later was implemented","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.472937Z","iopub.execute_input":"2024-07-07T19:30:51.473280Z","iopub.status.idle":"2024-07-07T19:30:51.498316Z","shell.execute_reply.started":"2024-07-07T19:30:51.473234Z","shell.execute_reply":"2024-07-07T19:30:51.497279Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Data Types\")\ndf.dtypes\n# Tackle data types for all columns","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.499622Z","iopub.execute_input":"2024-07-07T19:30:51.499905Z","iopub.status.idle":"2024-07-07T19:30:51.512595Z","shell.execute_reply.started":"2024-07-07T19:30:51.499871Z","shell.execute_reply":"2024-07-07T19:30:51.511676Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Null Values\")\ndf.isnull().sum()\n# I have a half empty file","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.513692Z","iopub.execute_input":"2024-07-07T19:30:51.513910Z","iopub.status.idle":"2024-07-07T19:30:51.528612Z","shell.execute_reply.started":"2024-07-07T19:30:51.513882Z","shell.execute_reply":"2024-07-07T19:30:51.527767Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Status'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.532067Z","iopub.execute_input":"2024-07-07T19:30:51.532367Z","iopub.status.idle":"2024-07-07T19:30:51.541264Z","shell.execute_reply.started":"2024-07-07T19:30:51.532333Z","shell.execute_reply":"2024-07-07T19:30:51.540336Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning\n- [X] Cleaning the Columns\n- [X] Fill null values\n- [X] Change Data Types\n- [X] Clean the Status Column\n- [X] Clean the Category Column \n- [ ] Clean Product_Num Column\n","metadata":{}},{"cell_type":"markdown","source":"## Cleaning the Column Name","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.542398Z","iopub.execute_input":"2024-07-07T19:30:51.542619Z","iopub.status.idle":"2024-07-07T19:30:51.553905Z","shell.execute_reply.started":"2024-07-07T19:30:51.542591Z","shell.execute_reply":"2024-07-07T19:30:51.553129Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Renaming columns for better use cases ('Down Date' to 'Down_Date')\ndf = df.rename(columns = {\"Down Date\":\"Down_Date\",'Product #':'Product_Num','Last Edited':'Fixed_Date','Mechanic Notes':'Mechanic_Notes','1 st attempt date':'1stdate', 'Edinger Part':'EdingerPart', 'Warner Part':'Warnerpart', 'Waterfront Part':'WaterfrontPart',\n       'Yorba Part':'YorbaPart','Part Comment':'PartComment','Attatchment feauture':'Pictures','Last Edited by':'Last_edited_by'})  \n# Dropping unwanted columns \ndf.drop(['Pictures','Last_edited_by','Reporter','EdingerPart', 'Warnerpart', 'WaterfrontPart', 'YorbaPart'],axis=1, inplace=True)\n# Sort values by Down_Date\ndf = df.sort_values('Down_Date')\n# Capatalizing the first letter of the Description column\ndf['Description'] = df['Description'].str.capitalize()\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.555105Z","iopub.execute_input":"2024-07-07T19:30:51.555359Z","iopub.status.idle":"2024-07-07T19:30:51.600662Z","shell.execute_reply.started":"2024-07-07T19:30:51.555321Z","shell.execute_reply":"2024-07-07T19:30:51.599740Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.602257Z","iopub.execute_input":"2024-07-07T19:30:51.602746Z","iopub.status.idle":"2024-07-07T19:30:51.608760Z","shell.execute_reply.started":"2024-07-07T19:30:51.602699Z","shell.execute_reply":"2024-07-07T19:30:51.607886Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill nulls ","metadata":{}},{"cell_type":"code","source":"# Dropping Rows with null values based on no information in Product or Location column\ndf = df.dropna(subset=['Location','Product'])\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.610282Z","iopub.execute_input":"2024-07-07T19:30:51.610764Z","iopub.status.idle":"2024-07-07T19:30:51.624359Z","shell.execute_reply.started":"2024-07-07T19:30:51.610702Z","shell.execute_reply":"2024-07-07T19:30:51.623464Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Status Column\n- [X] Label Unfinsihed reports as Not_complete","metadata":{}},{"cell_type":"code","source":"df['Status'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.625537Z","iopub.execute_input":"2024-07-07T19:30:51.626124Z","iopub.status.idle":"2024-07-07T19:30:51.632665Z","shell.execute_reply.started":"2024-07-07T19:30:51.626065Z","shell.execute_reply":"2024-07-07T19:30:51.631787Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace null values in the 'Status' column with 'Not_Complete'\ndf['Status'].fillna('Not_Complete', inplace=True)\n# Plot Not_Complete \nnot_complete = df[df['Status']=='Not_Complete']\ndf['Status'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.633944Z","iopub.execute_input":"2024-07-07T19:30:51.634287Z","iopub.status.idle":"2024-07-07T19:30:51.647025Z","shell.execute_reply.started":"2024-07-07T19:30:51.634252Z","shell.execute_reply":"2024-07-07T19:30:51.646071Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Change Data types","metadata":{}},{"cell_type":"code","source":"# convert 'Location', 'Categorical', 'Product', and 'Status' columns to categorical data type\ndf['Location'] = df['Location'].astype('category')\ndf['Category'] = df['Category'].astype('category')\ndf['Product'] = df['Product'].astype('category')\ndf['Status'] = df['Status'].astype('category')\n\n# convert 'Down_Date', 'Fixed_Date', and '1stdate' columns to pandas datetime data type\ndf['Down_Date'] = pd.to_datetime(df['Down_Date'])\ndf['Fixed_Date'] = pd.to_datetime(df['Fixed_Date'])\n\n# convert 'description' and 'Mechanic_Notes' columns to string data type\ndf['Description'] = df['Description'].astype(str)\ndf['Mechanic_Notes'] = df['Mechanic_Notes'].astype(str)\n\n# convert 'mechanic' column to categorical data type\ndf['Mechanic'] = df['Mechanic'].astype('category')\n\n# convert 'PartComment' column to string data type\ndf['PartComment'] = df['PartComment'].astype(str)\nprint('Cleaned Data Types')\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.648504Z","iopub.execute_input":"2024-07-07T19:30:51.649111Z","iopub.status.idle":"2024-07-07T19:30:51.694599Z","shell.execute_reply.started":"2024-07-07T19:30:51.649052Z","shell.execute_reply":"2024-07-07T19:30:51.693791Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Category Report Column\n- [X] Replace Mechanics Attention and Mechanic to Down\n- [X] Fill Null values with Down\n- [X] Drop maintainence routines and Cant Rent products\n","metadata":{}},{"cell_type":"code","source":"# replace 'Mechanics attention' to 'Down'\ndf = df.replace('Mechanics Attention', 'Down')\n\n# Replace Mechanic to Down\ndf= df.replace('Mechanic','Down')\n\n# Fill null values with 'Down'\ndf['Category'] = df['Category'].fillna('Down')\n\n# Deleting the ones that Can't be rented which would be an outliers in the dataset\ndf = df[df['Category'] != 'Cant rent']\n\n# Drop rows with 'Maintenance' in the 'Category' column which was the Maintenance category\ndf = df[df['Category'] != 'Maintaince']\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.695838Z","iopub.execute_input":"2024-07-07T19:30:51.696071Z","iopub.status.idle":"2024-07-07T19:30:51.709489Z","shell.execute_reply.started":"2024-07-07T19:30:51.696042Z","shell.execute_reply":"2024-07-07T19:30:51.708534Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Category'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.710874Z","iopub.execute_input":"2024-07-07T19:30:51.711262Z","iopub.status.idle":"2024-07-07T19:30:51.723949Z","shell.execute_reply.started":"2024-07-07T19:30:51.711211Z","shell.execute_reply":"2024-07-07T19:30:51.723044Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cleaning the Product Number column\n- [X] Clean junk that isn't a number\n- [X] Replace repair tag numbers to 0\n- [X] Create a unique number\n    - Set up sample for analysis later in specific bikes\n    - template: Location/product/product_num\n        - example: WaterfrontDouble_surrey5 or WFDS05\n","metadata":{}},{"cell_type":"code","source":"print('Null Values')\n# Fill null values in the 'Product_Num' column with 0\ndf['Product_Num'] = df['Product_Num'].fillna(0)\ndf['Product_Num'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.725238Z","iopub.execute_input":"2024-07-07T19:30:51.725524Z","iopub.status.idle":"2024-07-07T19:30:51.737496Z","shell.execute_reply.started":"2024-07-07T19:30:51.725489Z","shell.execute_reply":"2024-07-07T19:30:51.736654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Each location had product numbers. Example: (Chopper Edinger #3 was unique to location and product included)')\n\n# Remove all non-digit characters and trailing zeros from the 'Product_Num' column\ndf['Product_Num'] = df['Product_Num'].astype(str).replace('[^\\d]+|(?<=\\d)0+(?=\\d)', '', regex=True).str.rstrip('0')\ndf['Product_Num'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.738894Z","iopub.execute_input":"2024-07-07T19:30:51.739306Z","iopub.status.idle":"2024-07-07T19:30:51.753553Z","shell.execute_reply.started":"2024-07-07T19:30:51.739262Z","shell.execute_reply":"2024-07-07T19:30:51.752690Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Numbered_products will be used as a dataset we can do analysis on\")\n# Select rows where the 'Product_Num' column is not equal to '0'\nnumbered_products = df[df['Product_Num'] != '0']\nfig, ax = plt.subplots(figsize=(20,8))\nnumbered_products['Product'].hist(ax=ax)\n# Set axis labels and plot title\nax.set_xlabel('Year-Month')\nax.set_ylabel('Number of Reports')\nax.set_title('Histogram of the reports that has product numbers')\nprint(\"We can use these bikes to see how bike maintaince can behaves over time and dependent on Location\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:51.754778Z","iopub.execute_input":"2024-07-07T19:30:51.754997Z","iopub.status.idle":"2024-07-07T19:30:52.072878Z","shell.execute_reply.started":"2024-07-07T19:30:51.754970Z","shell.execute_reply":"2024-07-07T19:30:52.071976Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Error in product number, Product number at warner was repair tag id number, so Warner tags and potentially Edinger are inaccurate')\n# Convert 'Product_Num' column to numeric type\ndf['Product_Num'] = pd.to_numeric(df['Product_Num'], errors='coerce')\n\n# Filter for rows with 'Product_Num' greater than 30\nhigh_product_num = df[df['Product_Num'] > 30]\n\n# Print information about high product numbers\nfor index, row in high_product_num.iterrows():\n    print(f\"Product {row['Product']} from {row['Location']} has a Product_Num of {row['Product_Num']}.\")\n\n# Filter for rows with NaN values in the 'Product_Num' column\nnan_product_num = df[df['Product_Num'].isna()]\n\n# Define a lambda function to combine columns and handle missing values\ncombine_columns = lambda row: f\"{row['Location'].replace('Waterfront', 'W.A.').replace('Yorba Linda', 'Y.L.').replace('Edinger', 'M.E.').replace('Warner', 'M.W.')}_{row['Product']}_{row['Product_Num']}\" if pd.notnull(row['Product_Num']) else \"\"\n\n# Apply the lambda function to create a new column 'Location_Product_Num'\ndf['Location_Product_Num'] = df.apply(combine_columns, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.074008Z","iopub.execute_input":"2024-07-07T19:30:52.074292Z","iopub.status.idle":"2024-07-07T19:30:52.111323Z","shell.execute_reply.started":"2024-07-07T19:30:52.074261Z","shell.execute_reply":"2024-07-07T19:30:52.110308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Product_Num to 0 for repair tags at warner\ndf.loc[(df['Location'].str.contains('Warner')) & (df['Product_Num'] > 700), 'Product_Num'] = 0\n# drop row where mulitple cruisers were worked since it was supposed to be maintaince and not down bikes\ndf.drop(df[(df['Location'].str.contains('Waterfront')) & (df['Product_Num'] > 20000)].index, inplace=True)\n# Display the high numbers\nhigh_product_num = df[df['Product_Num'] > 30]\n\nfor index, row in high_product_num.iterrows():\n    print(f\"Product {row['Product']} from {row['Location']} has a Product_Num of {row['Product_Num']}.\")\n# the five outputs all have high number product numbers due to \n#transfers and based on the serial number  ","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.112755Z","iopub.execute_input":"2024-07-07T19:30:52.113554Z","iopub.status.idle":"2024-07-07T19:30:52.130739Z","shell.execute_reply.started":"2024-07-07T19:30:52.113502Z","shell.execute_reply":"2024-07-07T19:30:52.129831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Product_Num'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.131988Z","iopub.execute_input":"2024-07-07T19:30:52.132274Z","iopub.status.idle":"2024-07-07T19:30:52.147458Z","shell.execute_reply.started":"2024-07-07T19:30:52.132236Z","shell.execute_reply":"2024-07-07T19:30:52.146521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a YearMonth column","metadata":{}},{"cell_type":"code","source":"# Create a new column with the year and month extracted from the 'Date' column\ndf['YearMonth'] = df['Down_Date'].dt.strftime('%Y-%m')\n\n# Group the data by year and month, and count the number of reports in each group\nmonthly_count = df.groupby('YearMonth')['Down_Date'].count()\n\n# Plot the resulting data as a line graph\nplt.figure(figsize=(13, 8))\nplt.plot(monthly_count.index, monthly_count.values)\n\nplt.xlabel('Year-Month')\nplt.ylabel('Number of Reports')\nplt.title('Monthly Report Count')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.148907Z","iopub.execute_input":"2024-07-07T19:30:52.149218Z","iopub.status.idle":"2024-07-07T19:30:52.344494Z","shell.execute_reply.started":"2024-07-07T19:30:52.149175Z","shell.execute_reply":"2024-07-07T19:30:52.343569Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a Fixed Days Columns","metadata":{}},{"cell_type":"code","source":"# Create a new column called 'fixed_days'\ndf['Fixed_Days'] = (df['Fixed_Date'] - df['Down_Date']).dt.days\ndf['Fixed_Days'].hist()\nplt.title('Count of Fixed Days Historgram')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.345703Z","iopub.execute_input":"2024-07-07T19:30:52.345948Z","iopub.status.idle":"2024-07-07T19:30:52.531557Z","shell.execute_reply.started":"2024-07-07T19:30:52.345910Z","shell.execute_reply":"2024-07-07T19:30:52.530684Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify Outliers\n# Create a boolean mask to identify rows where Fixed_Days is over 35\nmask = df['Fixed_Days'] > 80\n\n# Use the mask to filter the original DataFrame and create a new variable\nfixed_days_over_80 = df[mask]\n\n# Display the new variable\nfixed_days_over_80['Fixed_Days'].hist()\nplt.title('Identify Outliers over 80 days')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.535849Z","iopub.execute_input":"2024-07-07T19:30:52.536122Z","iopub.status.idle":"2024-07-07T19:30:52.726846Z","shell.execute_reply.started":"2024-07-07T19:30:52.536076Z","shell.execute_reply":"2024-07-07T19:30:52.726032Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_days_over_80['Fixed_Days'].describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.728029Z","iopub.execute_input":"2024-07-07T19:30:52.728286Z","iopub.status.idle":"2024-07-07T19:30:52.738074Z","shell.execute_reply.started":"2024-07-07T19:30:52.728255Z","shell.execute_reply":"2024-07-07T19:30:52.737108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_days_85 = df[df['Fixed_Days'] == 85]\nfixed_days_85.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.739283Z","iopub.execute_input":"2024-07-07T19:30:52.739505Z","iopub.status.idle":"2024-07-07T19:30:52.764658Z","shell.execute_reply.started":"2024-07-07T19:30:52.739478Z","shell.execute_reply":"2024-07-07T19:30:52.763719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dec_30_reports = df[df['Fixed_Date']== '2020-12-30']\ndec_30_reports.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.766012Z","iopub.execute_input":"2024-07-07T19:30:52.766637Z","iopub.status.idle":"2024-07-07T19:30:52.790974Z","shell.execute_reply.started":"2024-07-07T19:30:52.766589Z","shell.execute_reply":"2024-07-07T19:30:52.790140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the drop() method to drop the selected rows\ndf = df.drop(dec_30_reports.index)\n# Verify that the rows have been dropped\ndf['Fixed_Days'].hist()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:52.792072Z","iopub.execute_input":"2024-07-07T19:30:52.792332Z","iopub.status.idle":"2024-07-07T19:30:53.010839Z","shell.execute_reply.started":"2024-07-07T19:30:52.792302Z","shell.execute_reply":"2024-07-07T19:30:53.009849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Fixed_Days'].hist()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.012096Z","iopub.execute_input":"2024-07-07T19:30:53.012356Z","iopub.status.idle":"2024-07-07T19:30:53.234801Z","shell.execute_reply.started":"2024-07-07T19:30:53.012323Z","shell.execute_reply":"2024-07-07T19:30:53.233928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Outliers of more than 80 days being down')\noutliers = df[df['Fixed_Days'] > 80]\noutliers.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.235946Z","iopub.execute_input":"2024-07-07T19:30:53.236193Z","iopub.status.idle":"2024-07-07T19:30:53.257205Z","shell.execute_reply.started":"2024-07-07T19:30:53.236161Z","shell.execute_reply":"2024-07-07T19:30:53.256329Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ordered Variable Dataframe","metadata":{}},{"cell_type":"code","source":"# Create a new DataFrame where the 'Status' column contains 'Order'\nordered_df = df[df['Status'].str.contains('Order') | df['Status'].str.contains('Received')]\nordered_df['Fixed_Days'].hist()\nplt.title('Reports that needed parts to be ordered or recieved with fixed days')","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.258636Z","iopub.execute_input":"2024-07-07T19:30:53.259391Z","iopub.status.idle":"2024-07-07T19:30:53.454266Z","shell.execute_reply.started":"2024-07-07T19:30:53.259341Z","shell.execute_reply":"2024-07-07T19:30:53.453242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"# Define a function to investigate outliers\ndef investigate_outliers(df, column):\n    # Create a boxplot to visualize the distribution and outliers\n    fig, ax = plt.subplots(figsize=(8,6))\n    ax.boxplot(df['Fixed_Days'])\n    ax.set_title(f\"Distribution and outliers in {column}\")\n    ax.set_ylabel(column)\n\n    # Calculate the upper and lower bounds for outliers\n    q1 = df['Fixed_Days'].quantile(0.25)\n    q3 = df['Fixed_Days'].quantile(0.75)\n    iqr = q3 - q1\n    upper_bound = q3 + 1.5 * iqr\n    lower_bound = q1 - 1.5 * iqr\n    \n    # Count the number of outliers\n    outliers = df[(df['Fixed_Days'] < lower_bound) | (df['Fixed_Days'] > upper_bound)]\n    num_outliers = len(outliers)\n    \n    # Print the number of outliers and their details\n    print(f\"\\nThere are {num_outliers} outliers in the {column} column:\")\n\n# Call the function to investigate outliers in the 'Days' column\ninvestigate_outliers(df, 'Fixed_Days')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.455666Z","iopub.execute_input":"2024-07-07T19:30:53.455912Z","iopub.status.idle":"2024-07-07T19:30:53.644236Z","shell.execute_reply.started":"2024-07-07T19:30:53.455879Z","shell.execute_reply":"2024-07-07T19:30:53.643368Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Medians and Averages by Locations","metadata":{}},{"cell_type":"code","source":"# Calculate average and median values by location and day\ngrouped = df.groupby(['Location', 'Down_Date']).mean().reset_index()\naverage_by_location = grouped.groupby('Location')['Fixed_Days'].mean()\nmedian_by_location = grouped.groupby('Location')['Fixed_Days'].median()\nfor location in df['Location'].unique():\n    print(f\"Location: {location}\")\n    print(f\"Average fixed days: {average_by_location[location]}\")\n    print(f\"Median fixed days: {median_by_location[location]}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.645788Z","iopub.execute_input":"2024-07-07T19:30:53.646028Z","iopub.status.idle":"2024-07-07T19:30:53.674014Z","shell.execute_reply.started":"2024-07-07T19:30:53.645997Z","shell.execute_reply":"2024-07-07T19:30:53.673174Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What was the busiest time of the year","metadata":{}},{"cell_type":"code","source":"# Count the frequency of each Down_Date value and sort in descending order\ndate_counts = df['Down_Date'].value_counts().sort_values(ascending=False)\n# Get the date with the highest count\nbusiest_date = date_counts.index[0]\n# Count the number of reports for the busiest date\nbusiest_date_count = date_counts[0]\nprint(f\"The busiest time of the year is {busiest_date} with {busiest_date_count} reports.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.675332Z","iopub.execute_input":"2024-07-07T19:30:53.675726Z","iopub.status.idle":"2024-07-07T19:30:53.684311Z","shell.execute_reply.started":"2024-07-07T19:30:53.675681Z","shell.execute_reply":"2024-07-07T19:30:53.683455Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Description Word Plot","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nall_words = ''\nfor arg in df[\"Description\"]: \n\n    tokens = arg.split()  \n      \n    all_words += \" \".join(tokens)+\" \"\n\nwordcloud = WordCloud(width = 700, height = 700, \n                background_color ='white', \n                min_font_size = 10).generate(all_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (13, 13), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:53.685490Z","iopub.execute_input":"2024-07-07T19:30:53.685708Z","iopub.status.idle":"2024-07-07T19:30:54.997231Z","shell.execute_reply.started":"2024-07-07T19:30:53.685681Z","shell.execute_reply":"2024-07-07T19:30:54.996356Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count the number of occurrences of each unique value in the Description column\ntop_descriptions = df['Description'].value_counts()\n\n# print the top 10 most frequent descriptions and their counts\nprint(\"Top Description Results:\")\nprint(top_descriptions.head(15))","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:54.998550Z","iopub.execute_input":"2024-07-07T19:30:54.999323Z","iopub.status.idle":"2024-07-07T19:30:55.007379Z","shell.execute_reply.started":"2024-07-07T19:30:54.999275Z","shell.execute_reply":"2024-07-07T19:30:55.006446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tire Related Problems Overtime","metadata":{}},{"cell_type":"code","source":"# Create a new column that contains a boolean value indicating whether the description contains the word \"tire\"\ndf[\"Has_Tire\"] = df[\"Description\"].str.contains(\"tire\")\n\n# Group the data by Down_Date and count the number of rows for each date that have a description containing the word \"tire\"\ntire_counts = df.groupby(\"YearMonth\")[\"Has_Tire\"].sum()\n# Create a histogram of the tire counts\nfig, ax = plt.subplots(figsize=(15, 6))\nax.hist(df[df[\"Has_Tire\"]][\"Down_Date\"], bins=15)\nax.set_title(\"Distribution of Maintenance Reports Containing 'Tire'\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Number of Reports\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:55.008759Z","iopub.execute_input":"2024-07-07T19:30:55.009375Z","iopub.status.idle":"2024-07-07T19:30:55.325458Z","shell.execute_reply.started":"2024-07-07T19:30:55.009331Z","shell.execute_reply":"2024-07-07T19:30:55.324436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tire_counts)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:55.326720Z","iopub.execute_input":"2024-07-07T19:30:55.326964Z","iopub.status.idle":"2024-07-07T19:30:55.332586Z","shell.execute_reply.started":"2024-07-07T19:30:55.326932Z","shell.execute_reply":"2024-07-07T19:30:55.331672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Chain Related Problems Overtime","metadata":{}},{"cell_type":"code","source":"# Create a new column that contains a boolean value indicating whether the description contains the word \"tire\"\ndf[\"Has_Chain\"] = df[\"Description\"].str.contains(\"chain\")\n\n# Group the data by Down_Date and count the number of rows for each date that have a description containing the word \"tire\"\nchain_counts = df.groupby(\"YearMonth\")[\"Has_Chain\"].sum()\n# Create a histogram of the tire counts\nfig, ax = plt.subplots(figsize=(15, 6))\nax.hist(df[df[\"Has_Chain\"]][\"Down_Date\"], bins=8)\nax.set_title(\"Distribution of Maintenance Reports Containing 'Chain'\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Number of Reports\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:55.333797Z","iopub.execute_input":"2024-07-07T19:30:55.334047Z","iopub.status.idle":"2024-07-07T19:30:55.590010Z","shell.execute_reply.started":"2024-07-07T19:30:55.334015Z","shell.execute_reply":"2024-07-07T19:30:55.589067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create a new column that contains a boolean value indicating whether the description contains the word \"brake\"\ndf[\"Has_Brake\"] = df[\"Description\"].str.contains(\"brake\")\n\n# Group the data by YearMonth and count the number of rows for each month that have a description containing the word \"brake\"\nbrake_counts = df.groupby(\"YearMonth\")[\"Has_Brake\"].sum()\n\n# Create a histogram of the brake counts\nfig, ax = plt.subplots(figsize=(15,6))\nax.hist(df[df[\"Has_Brake\"]][\"Down_Date\"], bins=9)\nax.set_title(\"Distribution of Maintenance Reports Containing 'Brake'\")\nax.set_xlabel(\"Number of Reports\")\nax.set_ylabel(\"Frequency\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:55.591459Z","iopub.execute_input":"2024-07-07T19:30:55.591770Z","iopub.status.idle":"2024-07-07T19:30:55.872843Z","shell.execute_reply.started":"2024-07-07T19:30:55.591728Z","shell.execute_reply":"2024-07-07T19:30:55.871994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Group the data by date and count the number of maintenance reports for each variable\ndf_count = df.groupby([\"Down_Date\"])[[\"Has_Tire\", \"Has_Chain\"]].sum()\n\n# Filter out any days with zero reports\ndf_count = df_count[(df_count.T != 0).any()]\n\n# Create a scatter plot of the count over time for both variables\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(df_count.index, df_count[\"Has_Tire\"], color='blue', alpha=0.5, label=\"Has Tire\")\nax.scatter(df_count.index, df_count[\"Has_Chain\"], color='green', alpha=0.5, label=\"Has Chain\")\nax.set_title(\"Count of Maintenance Reports with 'Tire' and 'Chain'\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Count of Maintenance Reports\")\nax.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:55.874010Z","iopub.execute_input":"2024-07-07T19:30:55.874293Z","iopub.status.idle":"2024-07-07T19:30:56.191942Z","shell.execute_reply.started":"2024-07-07T19:30:55.874260Z","shell.execute_reply":"2024-07-07T19:30:56.190975Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How much did ordering have an effect on the days to fix the products?","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,8))\nax.hist(ordered_df['Fixed_Days'], bins=15)\nax.set_title(\"Ordered Parts\")\nax.set_xlabel(\"Days\")\nax.set_ylabel(\"Frequency\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:56.193244Z","iopub.execute_input":"2024-07-07T19:30:56.193529Z","iopub.status.idle":"2024-07-07T19:30:56.443475Z","shell.execute_reply.started":"2024-07-07T19:30:56.193493Z","shell.execute_reply":"2024-07-07T19:30:56.442624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the median days to fix for the entire dataset and the ordered bikes\nmedian_all_bikes = df['Fixed_Date'].median()\nmedian_ordered_bikes = ordered_df['Fixed_Date'].median()\n\n# Create a histogram of days to fix for all bikes and ordered bikes\nplt.figure(figsize=(10,8))\nplt.hist(df['Fixed_Date'], alpha=0.5, label='All Bikes')\nplt.hist(ordered_df['Fixed_Date'], alpha=0.5, label='Ordered Bikes')\nplt.axvline(median_all_bikes, color='blue', linestyle='dashed', linewidth=1, label=f'Median All Bikes: {median_all_bikes:.1f}')\nplt.axvline(median_ordered_bikes, color='orange', linestyle='dashed', linewidth=1, label=f'Median Ordered Bikes: {median_ordered_bikes:.1f}')\nplt.xlabel('Days to Fix')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:56.444800Z","iopub.execute_input":"2024-07-07T19:30:56.446884Z","iopub.status.idle":"2024-07-07T19:30:56.789142Z","shell.execute_reply.started":"2024-07-07T19:30:56.446833Z","shell.execute_reply":"2024-07-07T19:30:56.788281Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a histogram to show the frequency of values\nfig, ax = plt.subplots(figsize=(10,8))\nax.hist(df['Fixed_Days'], bins=25)\nax.set_title(\"Histogram of all Products \")\nax.set_xlabel(\"Days\")\nax.set_ylabel(\"Frequency\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:56.790533Z","iopub.execute_input":"2024-07-07T19:30:56.791275Z","iopub.status.idle":"2024-07-07T19:30:57.271731Z","shell.execute_reply.started":"2024-07-07T19:30:56.791222Z","shell.execute_reply":"2024-07-07T19:30:57.270883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Productivity**","metadata":{}},{"cell_type":"code","source":"# group the data by month and calculate the average Days_to_Fix for each month\nmonthly_avg = df.groupby(pd.Grouper(key='Down_Date', freq='M'))['Fixed_Days'].mean()\n\n# plot the time series\nplt.figure(figsize=(13, 8))\nplt.plot(monthly_avg)\nplt.xlabel('Month')\nplt.ylabel('Average Days to Fix')\nplt.title('Time Series of Average Days to Fix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:57.272873Z","iopub.execute_input":"2024-07-07T19:30:57.273127Z","iopub.status.idle":"2024-07-07T19:30:57.523592Z","shell.execute_reply.started":"2024-07-07T19:30:57.273074Z","shell.execute_reply":"2024-07-07T19:30:57.522578Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sort_values('Down_Date')\n# Calculate the moving average\nwindow_size = 7  \n# Adjust the window size as needed\ndf['MovingAverage'] = df['Fixed_Days'].rolling(window=window_size).mean()\n\n# Create the scatter plot\nfig, ax = plt.subplots(figsize=(20, 10))\nax.scatter(df['Down_Date'], df['Fixed_Days'], label='Fixed Days', alpha=0.5)\n\n# Plot the moving average line\nax.plot(df['Down_Date'], df['MovingAverage'], color='red', label=f'{window_size}-Day Moving Average')\n\n# Set labels and title\nax.set_xlabel('Dates')\nax.set_ylabel('Days the Product was Down')\nax.set_title('Mechanic Productivity')\n\n# Add a legend\nax.legend()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:57.525192Z","iopub.execute_input":"2024-07-07T19:30:57.525423Z","iopub.status.idle":"2024-07-07T19:30:57.844769Z","shell.execute_reply.started":"2024-07-07T19:30:57.525395Z","shell.execute_reply":"2024-07-07T19:30:57.843761Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mechanic Notes Word Cloud","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\n# Get all words after \"need\" in the Mechanic_Notes column\nneed_words = ' '.join(df['Mechanic_Notes'].str.split('needs').str[1].dropna())\n# Generate word cloud\nwordcloud = WordCloud(width=800, height=800, background_color='white', colormap='Blues').generate(need_words)\n\n# Display word cloud\nplt.figure(figsize=(8, 8), facecolor=None)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:57.846071Z","iopub.execute_input":"2024-07-07T19:30:57.846378Z","iopub.status.idle":"2024-07-07T19:30:58.514017Z","shell.execute_reply.started":"2024-07-07T19:30:57.846339Z","shell.execute_reply":"2024-07-07T19:30:58.513145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fleet KPI\n","metadata":{}},{"cell_type":"markdown","source":"## Waterfront Fleet","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n# Filter the data for the Waterfront location\nwaterfront_data = df.loc[df['Location'] == 'Waterfront', :]\n\n# Create a boxplot of the quantity of products sold\nsns.boxplot(data=waterfront_data, y='Fixed_Days')\n\n# Set plot title and axis labels\nplt.title('Distribution of Product at Waterfront Location')\nplt.xlabel('Waterfront')\nplt.ylabel('Products')\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:58.515303Z","iopub.execute_input":"2024-07-07T19:30:58.515548Z","iopub.status.idle":"2024-07-07T19:30:58.678919Z","shell.execute_reply.started":"2024-07-07T19:30:58.515517Z","shell.execute_reply":"2024-07-07T19:30:58.678075Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mean Time to Repair KPI","metadata":{}},{"cell_type":"code","source":"# Calculate the MTTR\nmttr = df['Fixed_Days'].mean()\n\nprint(f\"The Mean Time To Repair (MTTR) is {mttr:.2f} days.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:58.680369Z","iopub.execute_input":"2024-07-07T19:30:58.681065Z","iopub.status.idle":"2024-07-07T19:30:58.686829Z","shell.execute_reply.started":"2024-07-07T19:30:58.681017Z","shell.execute_reply":"2024-07-07T19:30:58.685931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group the data by date and calculate the MTTR for each date\nmttr_by_date = df.groupby('Fixed_Date')['Fixed_Days'].mean()\n\n# Create a time series plot of the MTTR over time\nplt.figure(figsize=(20,6))\nplt.plot(mttr_by_date.index, mttr_by_date.values)\nplt.xlabel('Date')\nplt.ylabel('Mean Time To Repair (MTTR)')\nplt.title('MTTR over Time')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:58.687917Z","iopub.execute_input":"2024-07-07T19:30:58.688186Z","iopub.status.idle":"2024-07-07T19:30:58.961357Z","shell.execute_reply.started":"2024-07-07T19:30:58.688147Z","shell.execute_reply":"2024-07-07T19:30:58.960293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Repair Success Rate","metadata":{}},{"cell_type":"code","source":"# Group the data by unique bike and count the number of repairs\nnum_repairs = df.groupby('Location_Product_Num').size()\n\n# Filter the data to only include bikes that have been repaired more than 2 times\nfiltered_data = df[df['Location_Product_Num'].isin(num_repairs[num_repairs > 2].index)]\n\n# Sort the data by bike and repair date\nfiltered_data.sort_values(['Location_Product_Num', 'Down_Date'], inplace=True)\n\n# Calculate the time between each repair for each bike\nfiltered_data['Time_To_Next_Break'] = filtered_data.groupby('Location_Product_Num')['Down_Date'].diff()\n\n# Convert the time difference to days \nfiltered_data['Time_To_Next_Break'] = filtered_data['Time_To_Next_Break'].dt.days\n\n# Drop the first row for each bike (since it doesn't have a previous repair date)\nfiltered_data = filtered_data.groupby('Location_Product_Num').apply(lambda x: x.iloc[1:])\n\n# Plot the distribution of time between repairs\nplt.hist(filtered_data['Time_To_Next_Break'], bins=30)\nplt.xlabel('Days')\nplt.ylabel('Frequency')\nplt.title('Distribution of Time Between Repairs (Bikes Repaired > 2 Times)')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:58.963207Z","iopub.execute_input":"2024-07-07T19:30:58.963548Z","iopub.status.idle":"2024-07-07T19:30:59.283262Z","shell.execute_reply.started":"2024-07-07T19:30:58.963503Z","shell.execute_reply":"2024-07-07T19:30:59.282429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Most Prone Bike to Break ","metadata":{}},{"cell_type":"code","source":"# Group the data by unique bike and count the number of repairs\nnum_repairs = df.groupby('Location_Product_Num').size()\n\n# Sort the result in descending order\nmost_repaired_bike = df['Location_Product_Num'].value_counts().index[1]\nprint(f\"The bike with the most repairs is {most_repaired_bike}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:30:59.284815Z","iopub.execute_input":"2024-07-07T19:30:59.285247Z","iopub.status.idle":"2024-07-07T19:30:59.294364Z","shell.execute_reply.started":"2024-07-07T19:30:59.285201Z","shell.execute_reply":"2024-07-07T19:30:59.293381Z"},"trusted":true},"execution_count":null,"outputs":[]}]}